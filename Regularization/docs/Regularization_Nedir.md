# REGULARIZATION (DÃœZENLÄ°LEÅTÄ°RME) NEDÄ°R?

Yapay zeka ve makine Ã¶ÄŸrenmesi modelleri eÄŸitilirken karÅŸÄ±laÅŸÄ±lan en bÃ¼yÃ¼k problem **"Overfitting"** yani "AÅŸÄ±rÄ± Ã–ÄŸrenme/Ezberleme" problemidir. Model, eÄŸitim verisini o kadar iyi Ã¶ÄŸrenir ki (adeta ezberler), daha Ã¶nce hiÃ§ gÃ¶rmediÄŸi yeni veriler (test verisi veya gerÃ§ek hayat verisi) ile karÅŸÄ±laÅŸtÄ±ÄŸÄ±nda ne yapacaÄŸÄ±nÄ± bilemez ve hatalÄ± tahminler Ã¼retir.

Ä°ÅŸte **Regularization (DÃ¼zenlileÅŸtirme)**, bu ezberleme problemini engellemek iÃ§in kullanÄ±lan, modelin KayÄ±p (Loss) fonksiyonuna ekstra bir "ceza terimi" ekleyerek aÄŸÄ± daha basit ve genelleyici olmaya zorlayan matematiksel tekniklerin genel adÄ±dÄ±r.

---

## ğŸ“Œ Genel FormÃ¼l YapÄ±sÄ±

Makine Ã¶ÄŸrenmesinde hedefimiz `J(w)` (Maliyet/KayÄ±p Fonksiyonu) deÄŸerini en aza indirmektir. Normal bir modelin formÃ¼lÃ¼ ÅŸÃ¶yledir:

$$ J(w) = \frac{1}{m} \sum_{i=1}^{m} L(y_i, \hat{y}_i) $$

**Regularization eklediÄŸimizde ise formÃ¼l ÅŸu ÅŸekli alÄ±r:**

$$ J_{reg}(w) = \text{Orijinal KayÄ±p (Loss)} + \lambda \times \text{Ceza Terimi} $$

Burada **$\lambda$ (Lambda veya Alpha)** bizim cezanÄ±n ÅŸiddetini belirlediÄŸimiz **Hiperparametredir**. Lambda ne kadar bÃ¼yÃ¼k olursa ceza o kadar aÄŸÄ±r olur (Sizin projenizin `0.1` veya `0.01` olarak belirlediÄŸi L2 katsayÄ±sÄ±). 

---

## ğŸ“ 1. L1 Regularization (Lasso Regression)

L1 dÃ¼zenlileÅŸtirme, hata fonksiyonuna aÄŸÄ±rlÄ±klarÄ±n (weights) **mutlak deÄŸerlerinin toplamÄ±nÄ±** ceza olarak ekler.

### Matematiksel FormÃ¼lÃ¼:
$$ J(w) = \frac{1}{m} \sum_{i=1}^{m} L(y_i, \hat{y}_i) + \lambda \sum_{j=1}^{n} |w_j| $$

* **Ã–zelliÄŸi:** Matematiksel doÄŸasÄ± gereÄŸi, modeldeki gereksiz veya az Ã¶neme sahip parametrelerin/aÄŸÄ±rlÄ±klarÄ±n (weights) doÄŸrudan **SIFIR ($w=0$)** olmasÄ±nÄ± saÄŸlar. BÃ¶ylece, gereksiz Ã¶zellikleri tamamen devreden Ã§Ä±karÄ±r ve yerleÅŸik bir **Ã–zellik SeÃ§imi (Feature Selection)** yapar.

---

## ğŸ“ 2. L2 Regularization (Ridge Regression)

L2 dÃ¼zenlileÅŸtirme, hata fonksiyonuna aÄŸÄ±rlÄ±klarÄ±n **karelerinin toplamÄ±nÄ±** ceza olarak ekler. Deep Learning'de sÄ±kÃ§a kullanÄ±lÄ±r (sizin projenizde de bu kullanÄ±ldÄ±: `kernel_regularizer=regularizers.l2()`).

### Matematiksel FormÃ¼lÃ¼:
$$ J(w) = \frac{1}{m} \sum_{i=1}^{m} L(y_i, \hat{y}_i) + \lambda \sum_{j=1}^{n} w_j^2 $$

* **Ã–zelliÄŸi:** AÄŸÄ±rlÄ±klarÄ± asla tam sÄ±fÄ±r yapmaz ama **sÄ±fÄ±ra Ã§ok yaklaÅŸtÄ±rÄ±r**. BÃ¶ylece hiÃ§bir Ã¶zellik tamamen yok sayÄ±lmaz ama Ã¶zellikleri aÅŸÄ±rÄ± derecede baskÄ±n olan (hÄ±zlÄ± bÃ¼yÃ¼yen) parametreler tÃ¶rpÃ¼lenerek, ezberleme yeteneÄŸi elinden alÄ±nÄ±r.

---

## ğŸ¨ L1 ve L2'nin Geometrik GÃ¶sterimi (Grafik)

AÅŸaÄŸÄ±daki grafik L1 (Lasso) ve L2 (Ridge) yÃ¶ntemlerinin uzaydaki kÄ±sÄ±tlama bÃ¶lgelerini gÃ¶stermektedir.
 L1'in elmas (kare) ÅŸekli kÃ¶ÅŸeli olduÄŸu iÃ§in eksenleri kestiÄŸi noktalarda aÄŸÄ±rlÄ±klarÄ±n biri sÄ±fÄ±rlanma (0) eÄŸilimindedir. L2'nin dairesel yapÄ±sÄ± ise tÃ¼m aÄŸÄ±rlÄ±klarÄ± eÅŸit oranda sÄ±kÄ±ÅŸtÄ±rÄ±r, ama hiÃ§bir zaman kÃ¶ÅŸeye (sÄ±fÄ±ra) oturtmaz.

![L1 ve L2 Regularization GrafiÄŸi](../images/l1_l2_grafik.png)

---

## âš–ï¸ DiÄŸer Regularization Teknikleri

### 3. Elastic Net FormÃ¼lÃ¼
L1 ve L2 yÃ¶ntemlerinin karÄ±ÅŸÄ±mÄ±dÄ±r. Ä°ki yÃ¶ntemin de avantajlarÄ±nÄ± bir araya getirerek formÃ¼le edilir:

$$ J(w) = \text{Loss} + \lambda_1 \sum_{j=1}^{n} |w_j| + \lambda_2 \sum_{j=1}^{n} w_j^2 $$

### 4. Dropout (Derin Ã–ÄŸrenmeye Ã–zel)
Sinir aÄŸlarÄ±nda (Neural Networks) eÄŸitim sÄ±rasÄ±nda rastgele belirlenen bir yÃ¼zde oranÄ±nda (Ã¶rneÄŸin `%30`) bazÄ± nÃ¶ronlarÄ± geÃ§ici olarak **devreden Ã§Ä±kararak (kapatarak)** uygulanÄ±r.
* **MantÄ±ÄŸÄ±:** AÄŸdaki hiÃ§bir nÃ¶ron bir diÄŸerine kesin olarak gÃ¼venemez, bu yÃ¼zden iÅŸin kolayÄ±na kaÃ§Ä±p veri Ã¶zelliklerini ezberleyemez. Her nÃ¶ron daha baÄŸÄ±msÄ±z Ã§alÄ±ÅŸmak zorunda kalarak saÄŸlÄ±klÄ± Ã¶zellikler Ã¶ÄŸrenir. (Kodunuzdaki `layers.Dropout(0.3)` satÄ±rÄ±)

## ğŸ¯ Ã–zet
Regularization, Ã§ok iyi Ã§alÄ±ÅŸan ancak kendi ezberlediÄŸi ortamÄ±n dÄ±ÅŸÄ±na (Ã¶rneÄŸin Test setine veya hastaneye gelen yeni bir hastaya) Ã§Ä±ktÄ±ÄŸÄ±nda Ã§uvallayan bir Ã¶ÄŸrenciyi, gereksiz ayrÄ±ntÄ±lara boÄŸulmaktan kurtarÄ±p "iÅŸin mantÄ±ÄŸÄ±nÄ± kavramasÄ±" iÃ§in uyanÄ±k tutan bir ceza & denetim sistemidir.
